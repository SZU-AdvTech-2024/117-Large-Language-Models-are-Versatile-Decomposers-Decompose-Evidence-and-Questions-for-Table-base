      1 [main] bash (43408) D:\Git\usr\bin\bash.exe: *** fatal error in forked process - MEM_COMMIT failed, Win32 error 14./run_tabfact.sh: line 43:  3775 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 56:  3777 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 66:  3779 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 70:  3780 Segmentation fault      python eval.py
Press any key to continue...Select Col
Select Row
./run_tabfact.sh: line 34:  3781 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3782 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3784 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3786 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3787 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
-filling
./run_tabfact.sh: line 57:  3784 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3786 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3787 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3788 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3789 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3791 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3793 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3794 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3795 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3796 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3798 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3800 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3801 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3802 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3803 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3805 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3807 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3808 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3809 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3810 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3812 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3814 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3815 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3816 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3817 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3819 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3821 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3822 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3823 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3824 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3826 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3828 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3829 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
./run_tabfact.sh: line 34:  3830 Segmentation fault      python gen_sub_table.py
Decompose Question
./run_tabfact.sh: line 44:  3831 Segmentation fault      python filter_cloze.py
Run parsing-excution-filling
./run_tabfact.sh: line 57:  3833 Segmentation fault      python filling.py --dataset tabfact --dataset_split test
Run Final Reasoning
Reasoning -> Requset Codex
./run_tabfact.sh: line 67:  3835 Segmentation fault      python run_end2end.py
./run_tabfact.sh: line 71:  3836 Segmentation fault      python eval.py
Press any key to continue..../run_tabfact.sh: line 74: read: read error: 0: Input/output error
Select Col
Select Row
Traceback (most recent call last):
  File "gen_sub_table.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\groupby\generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\frame.py", line 129, in <module>
    from pandas.core import (
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
MemoryError
Decompose Question
Traceback (most recent call last):
  File "filter_cloze.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\arrays\__init__.py", line 11, in <module>
    from pandas.core.arrays.interval import IntervalArray
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\arrays\interval.py", line 82, in <module>
    from pandas.core.indexes.base import ensure_index
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\indexes\base.py", line 26, in <module>
    import pandas._libs.join as libjoin
ImportError: DLL load failed: 页面文件太小，无法完成操作。
Run parsing-excution-filling
Traceback (most recent call last):
  File "filling.py", line 7, in <module>
    import pandas as pd
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\api.py", line 29, in <module>
    from pandas.core.arrays import Categorical
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\arrays\__init__.py", line 11, in <module>
    from pandas.core.arrays.interval import IntervalArray
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\pandas\core\arrays\interval.py", line 82, in <module>
    from pandas.core.indexes.base import ensure_index
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 818, in get_code
  File "<frozen importlib._bootstrap_external>", line 917, in get_data
MemoryError
Run Final Reasoning
Reasoning -> Requset Codex
../..
Args info:
dataset: tab_fact
dataset_split: test
api_keys_file: key.txt
prompt_file: templates/tabfact/end2end.txt
save_dir: results
n_processes: 1
select_type: end2end
num_rows: 100
n_shots: 14
seed: 42
model_id: lechuang-gpt-4-turbo-bak
n_parallel_prompts: 1
max_generation_tokens: 150
max_api_total_tokens: 8001
temperature: 0.7
sampling_n: 1
top_p: 1.0
stop_tokens: ['\n\n']
verbose: True

******* Annotating *******
2024
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Users\86157\anaconda3\envs\dater\lib\multiprocessing\__init__.py", line 16, in <module>
    from . import context
  File "C:\Users\86157\anaconda3\envs\dater\lib\multiprocessing\context.py", line 3, in <module>
  File "C:\Users\86157\anaconda3\envs\dater\lib\threading.py", line 8, in <module>
  File "C:\Users\86157\anaconda3\envs\dater\lib\traceback.py", line 5, in <module>
    import linecache
  File "C:\Users\86157\anaconda3\envs\dater\lib\linecache.py", line 11, in <module>
    import tokenize
  File "C:\Users\86157\anaconda3\envs\dater\lib\tokenize.py", line 94, in <module>
    class TokenInfo(collections.namedtuple('TokenInfo', 'type string start end line')):
  File "C:\Users\86157\anaconda3\envs\dater\lib\collections\__init__.py", line 397, in namedtuple
    exec(s, namespace)
MemoryError
Traceback (most recent call last):
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2150, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "C:\Users\86157\anaconda3\envs\dater\lib\importlib\__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\tokenization_utils.py", line 27, in <module>
    from .tokenization_utils_base import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\tokenization_utils_base.py", line 74, in <module>
    from tokenizers import AddedToken
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\tokenizers\__init__.py", line 79, in <module>
    from .tokenizers import (
ImportError: DLL load failed: 页面文件太小，无法完成操作。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2150, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "C:\Users\86157\anaconda3\envs\dater\lib\importlib\__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\models\__init__.py", line 19, in <module>
    from . import (
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\models\layoutlm\__init__.py", line 22, in <module>
    from .configuration_layoutlm import LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP, LayoutLMConfig
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\models\layoutlm\configuration_layoutlm.py", line 19, in <module>
    from transformers import PretrainedConfig, PreTrainedTokenizer, TensorType
  File "<frozen importlib._bootstrap>", line 1032, in _handle_fromlist
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2140, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2154, in _get_module
    ) from e
RuntimeError: Failed to import transformers.tokenization_utils because of the following error (look up to see its traceback):
DLL load failed: 页面文件太小，无法完成操作。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "run_end2end.py", line 327, in <module>
    res_dic = main()
  File "run_end2end.py", line 256, in main
    from transformers import AutoTokenizer
  File "<frozen importlib._bootstrap>", line 1032, in _handle_fromlist
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2140, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "C:\Users\86157\anaconda3\envs\dater\lib\site-packages\transformers\file_utils.py", line 2154, in _get_module
    ) from e
RuntimeError: Failed to import transformers.models.auto because of the following error (look up to see its traceback):
Failed to import transformers.tokenization_utils because of the following error (look up to see its traceback):
DLL load failed: 页面文件太小，无法完成操作。
Select Col
Select Row
      0 [main] bash 3740 dofork: child -1 - forked process 54744 died unexpectedly, retry 0, exit code 0xC000026B, errno 11
./run_tabfact.sh: fork: retry: Resource temporarily unavailable
1035009 [main] bash 3740 dofork: child -1 - forked process 8488 died unexpectedly, retry 0, exit code 0xC000026B, errno 11
./run_tabfact.sh: fork: retry: Resource temporarily unavailable
3061927 [main] bash 3740 dofork: child -1 - forked process 1536 died unexpectedly, retry 0, exit code 0xC000026B, errno 11
./run_tabfact.sh: fork: retry: Resource temporarily unavailable
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
Select Col
Select Row
      0 [main] bash 3847 child_copy: user heap read copy failed, 0x800000000..0x8018C0000, done 3727360, windows pid 15224, Win32 error 299
   2034 [main] bash 3847 child_copy: data read copy failed, 0x1004E5000..0x1004EDE20, done 0, windows pid 15224, Win32 error 299
